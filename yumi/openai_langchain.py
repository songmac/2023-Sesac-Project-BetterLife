import os
import panel as pn
from dotenv import load_dotenv
import json, requests
import gradio as gr

from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from typing import Optional
from pydantic import BaseModel

# Load .env
load_dotenv()
api_key = os.environ.get('OPEN_API_KEY')

class CustomAIMessage(AIMessage):
    questions: Optional[list[str]] = None

class ExerciseChatBot:
    def __init__(self):
        self.llm = ChatOpenAI(
            temperature=1.0,
            model='gpt-3.5-turbo-0613',
            openai_api_key=api_key
        )

    def interact_with_model(self, user_input):
        # Langchainì—ì„œ ì‚¬ìš©í•  í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ í¬ë§· ë³€ê²½
        history_langchain_format = [SystemMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤.")]

        # AIMessage ëŒ€ì‹ ì— CustomAIMessageë¥¼ ì‚¬ìš©
        custom_ai_message = CustomAIMessage(content=user_input, questions=[
            "1. ë‚˜ì´ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "2. ìš´ë™ ëª©í‘œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”. (1: ì²´ë ¥ë‹¨ë ¨, 2: ì‹¬íê¸°ëŠ¥ë‹¨ë ¨)",
        ])
        
        history_langchain_format.append(custom_ai_message)

        try:
            gpt_response = self.llm(history_langchain_format)
            return gpt_response.content
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤ ì…ë ¥ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”"
        
exercise_chat_bot_instance = ExerciseChatBot()

gr.ChatInterface(
    fn=exercise_chat_bot_instance.interact_with_model,
    textbox=gr.Textbox(placeholder="ì…ë ¥", container=False, scale=5),
    # ì±„íŒ…ì°½ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•œë‹¤.
    chatbot=gr.Chatbot(height=400),
    title="ìš´ë™ í”„ë¡œê·¸ë¨ ì¶”ì²œ ì‹œìŠ¤í…œ",
    description="ìš´ë™í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•´ ì£¼ëŠ” ì±—ë´‡ ì…ë‹ˆë‹¤",
    theme="soft",
    retry_btn="ë‹¤ì‹œë³´ë‚´ê¸° â†©",
    undo_btn="ì´ì „ì±— ì‚­ì œ âŒ",
    clear_btn="ì „ì±— ì‚­ì œ ğŸ’«",
).launch()